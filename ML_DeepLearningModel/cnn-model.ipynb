{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport pickle\nimport pandas as pd\nimport numpy as np\nimport seaborn as sn\nimport keras\nfrom keras.preprocessing import text, sequence\nfrom keras.layers import Input, Dense, Embedding, Flatten, Conv1D, MaxPooling1D, Bidirectional, LSTM, GRU, concatenate, GlobalMaxPooling1D, GlobalAveragePooling1D, SpatialDropout1D\nfrom keras.layers import Reshape, Flatten, Dropout, Concatenate\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Model, Sequential\nfrom keras import backend as K\nfrom sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\nfrom tensorflow.keras.callbacks import EarlyStopping\nearly_stop=EarlyStopping(monitor='loss', patience=10)#, verbose=1)\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nlb_enc = LabelEncoder()\nimport nltk\nimport string ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-24T04:07:23.807282Z","iopub.execute_input":"2023-05-24T04:07:23.807671Z","iopub.status.idle":"2023-05-24T04:07:31.320095Z","shell.execute_reply.started":"2023-05-24T04:07:23.807637Z","shell.execute_reply":"2023-05-24T04:07:31.319141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_excel('/kaggle/input/spam-review-detection/data_train.xlsx')\ndata_dev = pd.read_excel('/kaggle/input/spam-review-detection/data_dev.xlsx')\ndata_test = pd.read_excel('/kaggle/input/spam-review-detection/data_test.xlsx')","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:07:31.323293Z","iopub.execute_input":"2023-05-24T04:07:31.324365Z","iopub.status.idle":"2023-05-24T04:07:37.967647Z","shell.execute_reply.started":"2023-05-24T04:07:31.324326Z","shell.execute_reply":"2023-05-24T04:07:37.966636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = lb_enc.fit_transform(data_train['Label'])\n\ny_dev = lb_enc.fit_transform(data_dev['Label'])\n\ny_test = lb_enc.fit_transform(data_test['Label'])","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:07:47.584158Z","iopub.execute_input":"2023-05-24T04:07:47.585026Z","iopub.status.idle":"2023-05-24T04:07:47.592571Z","shell.execute_reply.started":"2023-05-24T04:07:47.584981Z","shell.execute_reply":"2023-05-24T04:07:47.591573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer() \ntokenizer.fit_on_texts(data_train['transformed_text'])\ntokenizer.fit_on_texts(data_dev['transformed_text'])\ntokenizer.fit_on_texts(data_test['transformed_text'])\n\ntext_to_sequence_train = tokenizer.texts_to_sequences(data_train['transformed_text']) \ntext_to_sequence_dev = tokenizer.texts_to_sequences(data_dev['transformed_text']) \ntext_to_sequence_test = tokenizer.texts_to_sequences(data_test['transformed_text']) ","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:07:50.258890Z","iopub.execute_input":"2023-05-24T04:07:50.259262Z","iopub.status.idle":"2023-05-24T04:07:51.195784Z","shell.execute_reply.started":"2023-05-24T04:07:50.259231Z","shell.execute_reply":"2023-05-24T04:07:51.194916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length_sequence_train = max([len(i) for i in text_to_sequence_train])\n \npadded_train = pad_sequences(text_to_sequence_train, maxlen=max_length_sequence_train, \n                                    padding = \"pre\") \nmax_length_sequence_train\npadded_train","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:07:52.739541Z","iopub.execute_input":"2023-05-24T04:07:52.739910Z","iopub.status.idle":"2023-05-24T04:07:52.820719Z","shell.execute_reply.started":"2023-05-24T04:07:52.739881Z","shell.execute_reply":"2023-05-24T04:07:52.819647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"padded_dev = pad_sequences(text_to_sequence_dev, maxlen=max_length_sequence_train, \n                                    padding = \"pre\") \nlen(padded_dev)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:07:55.508922Z","iopub.execute_input":"2023-05-24T04:07:55.509272Z","iopub.status.idle":"2023-05-24T04:07:55.526869Z","shell.execute_reply.started":"2023-05-24T04:07:55.509246Z","shell.execute_reply":"2023-05-24T04:07:55.525969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"padded_test = pad_sequences(text_to_sequence_test, maxlen=max_length_sequence_train, \n                                    padding = \"pre\") \nlen(padded_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:07:56.995494Z","iopub.execute_input":"2023-05-24T04:07:56.995855Z","iopub.status.idle":"2023-05-24T04:07:57.033576Z","shell.execute_reply.started":"2023-05-24T04:07:56.995826Z","shell.execute_reply":"2023-05-24T04:07:57.032529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embed_size = 400 # how big is each word vector\nmax_features = 10000","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:07:58.505821Z","iopub.execute_input":"2023-05-24T04:07:58.506402Z","iopub.status.idle":"2023-05-24T04:07:58.517757Z","shell.execute_reply.started":"2023-05-24T04:07:58.506358Z","shell.execute_reply":"2023-05-24T04:07:58.516769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VOC_SIZE = len(tokenizer.word_index)+1\nembedding_matrix = np.zeros((VOC_SIZE, embed_size))\n\ndef get_model():\n    inp = Input(shape=(max_length_sequence_train,), dtype='int32')\n    x = Embedding(VOC_SIZE ,embed_size,weights=[embedding_matrix])(inp)\n    x = SpatialDropout1D(0.3)(x)\n    \n    conv_0 = Conv1D(128, kernel_size=3, kernel_initializer='normal', padding='valid', activation='elu')(x)    \n    maxpool_0 = MaxPooling1D(3, strides=1, padding='valid')(conv_0)\n    \n    conv_1 = Conv1D(128, kernel_size=5, kernel_initializer='normal', padding='valid', activation='elu')(x)    \n    maxpool_1 = MaxPooling1D(3, strides=1, padding='valid')(conv_1)\n    \n    conv_2 = Conv1D(128, kernel_size=6, kernel_initializer='normal', padding='valid', activation='elu')(x)    \n    maxpool_2 = MaxPooling1D(3, strides=1, padding='valid')(conv_2)\n    \n    z = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2]) \n#     flatten = Flatten()(z)\n#     dropout = Dropout(drop)(flatten)\n    z = Bidirectional(GRU(40, return_sequences=True))(z)\n    avg_pool = GlobalAveragePooling1D()(z)\n    max_pool = GlobalMaxPooling1D()(z)\n    conc = concatenate([avg_pool, max_pool])\n    outp = Dense(1, activation=\"sigmoid\")(conc)\n    model = Model(inputs=inp, outputs=outp)\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:08:00.272174Z","iopub.execute_input":"2023-05-24T04:08:00.272615Z","iopub.status.idle":"2023-05-24T04:08:00.285669Z","shell.execute_reply.started":"2023-05-24T04:08:00.272581Z","shell.execute_reply":"2023-05-24T04:08:00.284775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:08:02.974182Z","iopub.execute_input":"2023-05-24T04:08:02.974631Z","iopub.status.idle":"2023-05-24T04:08:06.325167Z","shell.execute_reply.started":"2023-05-24T04:08:02.974590Z","shell.execute_reply":"2023-05-24T04:08:06.324409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(padded_train, y_train,epochs=40, batch_size=64, \n                        validation_data=(padded_dev, y_dev), callbacks = [early_stop], verbose= 2)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:08:12.336913Z","iopub.execute_input":"2023-05-24T04:08:12.337773Z","iopub.status.idle":"2023-05-24T04:18:49.262264Z","shell.execute_reply.started":"2023-05-24T04:08:12.337707Z","shell.execute_reply":"2023-05-24T04:18:49.261108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sms_test = ['quyểnnnnnnnnnnnnnnnnnnnn vở này đẹp nhaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa']\nsms_seq = tokenizer.texts_to_sequences(sms_test)\n\nsms_pad = pad_sequences(sms_seq, maxlen=max_length_sequence_train, padding='pre')\n# tokenizer.fit_on_texts\nsms_pad\nmodel.predict(sms_pad)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:19:07.113926Z","iopub.execute_input":"2023-05-24T04:19:07.114287Z","iopub.status.idle":"2023-05-24T04:19:07.861148Z","shell.execute_reply.started":"2023-05-24T04:19:07.114259Z","shell.execute_reply":"2023-05-24T04:19:07.860212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(padded_train)\ny_pred_train = np.round(y_pred)\n\n# Evaluate performance on test set\nacc = accuracy_score(y_train, y_pred_train)\nprec = precision_score(y_train, y_pred_train)\ny_pred_classes_train = np.round(y_pred_train)\n# y_pred_classes = np.argmax(y_pred, axis=1)\nf1_macro = f1_score(y_train, y_pred_classes_train, average='macro')\ncm = confusion_matrix(y_train, y_pred_train)\nprint(\"Accuracy: \", acc)\nprint(\"Precision: \", prec)\nprint(\"F1 Macro: \", f1_macro)\nprint(\"Confusion Matrix: \\n\", cm)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:19:14.751133Z","iopub.execute_input":"2023-05-24T04:19:14.751577Z","iopub.status.idle":"2023-05-24T04:19:22.623756Z","shell.execute_reply.started":"2023-05-24T04:19:14.751541Z","shell.execute_reply":"2023-05-24T04:19:22.622763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(padded_dev)\ny_pred_dev = np.round(y_pred)\n\n# Evaluate performance on test set\nacc = accuracy_score(y_dev, y_pred_dev)\nprec = precision_score(y_dev, y_pred_dev)\ny_pred_classes_dev = np.round(y_pred_dev)\nf1_macro = f1_score(y_dev, y_pred_classes_dev, average='macro')\ncm = confusion_matrix(y_dev, y_pred_dev)\nprint(\"Accuracy: \", acc)\nprint(\"Precision: \", prec)\nprint(\"F1 Macro: \", f1_macro)\nprint(\"Confusion Matrix: \\n\", cm)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:19:26.715073Z","iopub.execute_input":"2023-05-24T04:19:26.715411Z","iopub.status.idle":"2023-05-24T04:19:27.898642Z","shell.execute_reply.started":"2023-05-24T04:19:26.715386Z","shell.execute_reply":"2023-05-24T04:19:27.897651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(padded_test)\ny_pred_test = np.round(y_pred)\n\n# Evaluate performance on test set\nacc = accuracy_score(y_test, y_pred_test)\nprec = precision_score(y_test, y_pred_test)\ny_pred_classes_test = np.round(y_pred_test)\n# y_pred_classes = np.argmax(y_pred, axis=1)\nf1_macro = f1_score(y_test, y_pred_classes_test, average='macro')\ncm = confusion_matrix(y_test, y_pred_test)\nprint(\"Accuracy: \", acc)\nprint(\"Precision: \", prec)\nprint(\"F1 Macro: \", f1_macro)\nprint(\"Confusion Matrix: \\n\", cm)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T04:19:33.115687Z","iopub.execute_input":"2023-05-24T04:19:33.116664Z","iopub.status.idle":"2023-05-24T04:19:35.690174Z","shell.execute_reply.started":"2023-05-24T04:19:33.116622Z","shell.execute_reply":"2023-05-24T04:19:35.689202Z"},"trusted":true},"execution_count":null,"outputs":[]}]}